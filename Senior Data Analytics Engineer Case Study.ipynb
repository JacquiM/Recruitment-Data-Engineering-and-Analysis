{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recruitment Case Study\n",
    "\n",
    "The outcome of this technical assessment is to create two models that can be used by analysts to derive value and answers from the questions that they have. \n",
    "\n",
    "<b>Please note</b> that the code in this notebook does not include a sophisticated logging strategy as the strategy used within the business environment would need to be applied before this is put into production. Jupyter Notebook was used for this as it is a user-friendly option of explaining the thought process throughout the assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Input Datasets\n",
    "\n",
    "Extract raw data from the csv files that have been provided by Yoco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the base path to point to where the csv files are stored\n",
    "file_path = 'Data'\n",
    "\n",
    "# Read csv files from the base file path\n",
    "df_application = pd.read_csv(r'%s\\application.csv' % file_path)\n",
    "df_department = pd.read_csv(r'%s\\department.csv' % file_path)\n",
    "df_interview = pd.read_csv(r'%s\\interview.csv' % file_path)\n",
    "df_job = pd.read_csv(r'%s\\job.csv' % file_path)\n",
    "df_job_application = pd.read_csv(r'%s\\job_application.csv' % file_path)\n",
    "df_job_department = pd.read_csv(r'%s\\job_department.csv' % file_path)\n",
    "df_job_post = pd.read_csv(r'%s\\job_post.csv' % file_path)\n",
    "df_job_stage = pd.read_csv(r'%s\\job_stage.csv' % file_path)\n",
    "df_scheduled_interview = pd.read_csv(r'%s\\scheduled_interview.csv' % file_path)\n",
    "df_scheduled_interviewer = pd.read_csv(r'%s\\scheduled_interviewer.csv' % file_path)\n",
    "\n",
    "# List of datasets\n",
    "dataset_names = [\"df_application\", \"df_department\", \"df_interview\", \"df_job\", \"df_job_application\", \"df_job_department\", \"df_job_post\", \"df_job_stage\", \"df_scheduled_interview\", \"df_scheduled_interviewer\"]\n",
    "datasets = [df_application, df_department, df_interview, df_job, df_job_application, df_job_department, df_job_post, df_job_stage, df_scheduled_interview, df_scheduled_interviewer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "Analyse the data to understand the relationship between the datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Data Structure: All Columns (per Dataset)\n",
    "By viewing all columns in each dataset, an understanding of the existing raw data structure maybe be developed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Columns</th>\n",
       "      <th>Number of Columns</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Number of Records</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Index(['id', 'candidate_id', 'applied_at', 're...</td>\n",
       "      <td>18</td>\n",
       "      <td>df_application</td>\n",
       "      <td>6048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Index(['id', 'job_id', 'title', 'internal', 'e...</td>\n",
       "      <td>13</td>\n",
       "      <td>df_job_post</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Index(['id', 'application_id', 'location', 'st...</td>\n",
       "      <td>12</td>\n",
       "      <td>df_scheduled_interview</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Index(['id', 'name', 'created_at', 'updated_at...</td>\n",
       "      <td>7</td>\n",
       "      <td>df_job_stage</td>\n",
       "      <td>856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Index(['id', 'parent_id', 'name', 'external_id...</td>\n",
       "      <td>6</td>\n",
       "      <td>df_department</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Index(['id', 'name', 'status', 'created_at', '...</td>\n",
       "      <td>5</td>\n",
       "      <td>df_job</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Index(['scheduled_interview_id', 'interviewer_...</td>\n",
       "      <td>4</td>\n",
       "      <td>df_scheduled_interviewer</td>\n",
       "      <td>3694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Index(['job_stage_id', 'id', 'name'], dtype='o...</td>\n",
       "      <td>3</td>\n",
       "      <td>df_interview</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Index(['application_id', 'job_id', '_fivetran_...</td>\n",
       "      <td>3</td>\n",
       "      <td>df_job_application</td>\n",
       "      <td>14456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Index(['job_id', 'department_id', '_fivetran_s...</td>\n",
       "      <td>3</td>\n",
       "      <td>df_job_department</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Columns Number of Columns  \\\n",
       "0  Index(['id', 'candidate_id', 'applied_at', 're...                18   \n",
       "6  Index(['id', 'job_id', 'title', 'internal', 'e...                13   \n",
       "8  Index(['id', 'application_id', 'location', 'st...                12   \n",
       "7  Index(['id', 'name', 'created_at', 'updated_at...                 7   \n",
       "1  Index(['id', 'parent_id', 'name', 'external_id...                 6   \n",
       "3  Index(['id', 'name', 'status', 'created_at', '...                 5   \n",
       "9  Index(['scheduled_interview_id', 'interviewer_...                 4   \n",
       "2  Index(['job_stage_id', 'id', 'name'], dtype='o...                 3   \n",
       "4  Index(['application_id', 'job_id', '_fivetran_...                 3   \n",
       "5  Index(['job_id', 'department_id', '_fivetran_s...                 3   \n",
       "\n",
       "                    Dataset Number of Records  \n",
       "0            df_application              6048  \n",
       "6               df_job_post               261  \n",
       "8    df_scheduled_interview               846  \n",
       "7              df_job_stage               856  \n",
       "1             df_department                24  \n",
       "3                    df_job               102  \n",
       "9  df_scheduled_interviewer              3694  \n",
       "2              df_interview              2242  \n",
       "4        df_job_application             14456  \n",
       "5         df_job_department               243  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe to store dataset column information\n",
    "df_dataset_columns = pd.DataFrame(columns={'Dataset','Number of Columns', 'Columns', 'Number of Records'})\n",
    "\n",
    "# Show all columns of each dataframe\n",
    "for index, dataset in enumerate(datasets):\n",
    "    \n",
    "    # Test Harness: Print dataset names and columns of each dataset\n",
    "    #print(dataset_names[index])\n",
    "    #print(dataset.columns)\n",
    "    \n",
    "    # Append a row for each dataset with number of columns\n",
    "    df_dataset_columns = df_dataset_columns.append({'Dataset':dataset_names[index],'Number of Columns':len(dataset.columns), 'Columns':str(dataset.columns), 'Number of Records': len(dataset)}, ignore_index=True)\n",
    "\n",
    "# Display the table of columns per dataset in descending order (by Number of Columns)\n",
    "df_dataset_columns.sort_values(by=['Number of Columns'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen from the above that the datasets with the most columns are 'application' and 'job_post'. From this view of the data, there are already a few identifying factors of certain datasets. For example, job_application, job_department and scheduled_interviewer are associative entities that tie together data from different datasets. Most data (exluding associative data) seems to live in the <b>application</b> and <b>interview</b> datasets.\n",
    "\n",
    "Since the application and interview datasets contain the most data, these two should form the foundation of the models that need to be created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Relationship Between Datasets: All Tables\n",
    "The definition (fact/associative, dimension/lookup) of each table may be determined by the number of potential relationships to the table\n",
    "\n",
    "Please note: Since there are datasets that have been excluded, this needs to be narrowed down to available datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relationship Columns</th>\n",
       "      <th>Number of Relationships</th>\n",
       "      <th>Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['candidate_id', 'source_id', 'rejected_reason...</td>\n",
       "      <td>8</td>\n",
       "      <td>df_application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['application_id', 'interview_id', 'organizer_...</td>\n",
       "      <td>3</td>\n",
       "      <td>df_scheduled_interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['scheduled_interview_id', 'interviewer_id', '...</td>\n",
       "      <td>3</td>\n",
       "      <td>df_scheduled_interviewer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['parent_id', 'external_id']</td>\n",
       "      <td>2</td>\n",
       "      <td>df_department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['application_id', 'job_id']</td>\n",
       "      <td>2</td>\n",
       "      <td>df_job_application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['job_id', 'department_id']</td>\n",
       "      <td>2</td>\n",
       "      <td>df_job_department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['job_stage_id']</td>\n",
       "      <td>1</td>\n",
       "      <td>df_interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['job_id']</td>\n",
       "      <td>1</td>\n",
       "      <td>df_job_post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['job_id']</td>\n",
       "      <td>1</td>\n",
       "      <td>df_job_stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>df_job</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Relationship Columns Number of Relationships  \\\n",
       "0  ['candidate_id', 'source_id', 'rejected_reason...                       8   \n",
       "8  ['application_id', 'interview_id', 'organizer_...                       3   \n",
       "9  ['scheduled_interview_id', 'interviewer_id', '...                       3   \n",
       "1                       ['parent_id', 'external_id']                       2   \n",
       "4                       ['application_id', 'job_id']                       2   \n",
       "5                        ['job_id', 'department_id']                       2   \n",
       "2                                   ['job_stage_id']                       1   \n",
       "6                                         ['job_id']                       1   \n",
       "7                                         ['job_id']                       1   \n",
       "3                                                 []                       0   \n",
       "\n",
       "                    Dataset  \n",
       "0            df_application  \n",
       "8    df_scheduled_interview  \n",
       "9  df_scheduled_interviewer  \n",
       "1             df_department  \n",
       "4        df_job_application  \n",
       "5         df_job_department  \n",
       "2              df_interview  \n",
       "6               df_job_post  \n",
       "7              df_job_stage  \n",
       "3                    df_job  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create relationship stats dataframe\n",
    "df_dataset_relationships = pd.DataFrame(columns={'Dataset', 'Number of Relationships', 'Relationship Columns'})\n",
    "\n",
    "# Show possible relations of each dataframe\n",
    "for index, dataset in enumerate(datasets):\n",
    "    \n",
    "    # Filter dataset columns by columns that contain 'id' but are not equal to 'id'\n",
    "    relationship_columns = list(filter(lambda k: ('id' in k) and (k != 'id'), dataset.columns))\n",
    "    \n",
    "    # Append new stats record per dataset\n",
    "    df_dataset_relationships = df_dataset_relationships.append({'Dataset':dataset_names[index], 'Number of Relationships':len(relationship_columns), 'Relationship Columns': str(relationship_columns)}, ignore_index=True)\n",
    "\n",
    "    # Test Harness: Print dataset name and relationship columns\n",
    "    #print(dataset_names[index])\n",
    "    #print(relationship_columns)\n",
    "    \n",
    "# Print sorted dataframe based on number of relationships\n",
    "df_dataset_relationships.sort_values(by=['Number of Relationships'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, it can be seen that tables with more than one relationship could be considered associative/fact tables. In a case where there is only one relationship, the deduction is that these table \"may be\" considered as dimension or lookup tables.\n",
    "\n",
    "Based on that, the following has been deduced:\n",
    "\n",
    "- Possible fact/associative tables:\n",
    "    * df_application\n",
    "    * df_scheduled_interview\n",
    "    * df_scheduled_interviewer\n",
    "    * df_job_application\n",
    "    * df_job_department\n",
    "    \n",
    "- Possible dimension/lookup tables:\n",
    "    * df_department\n",
    "    * df_interview\n",
    "    * df_job_post\n",
    "    * df_job_stage\n",
    "\n",
    "- Other:\n",
    "    * df_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Relationship Between Datasets: Available Tables\n",
    "The above relationships are further investigated according to the datasets that have been made available. Since all tables have an 'id' column, some relationships had to be derived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>df_application</th>\n",
       "      <th>df_department</th>\n",
       "      <th>df_interview</th>\n",
       "      <th>df_job</th>\n",
       "      <th>df_job_application</th>\n",
       "      <th>df_job_department</th>\n",
       "      <th>df_job_post</th>\n",
       "      <th>df_job_stage</th>\n",
       "      <th>df_scheduled_interview</th>\n",
       "      <th>df_scheduled_interviewer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>df_application</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_department</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_interview</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_job</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_job_application</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_job_department</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_job_post</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_job_stage</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_scheduled_interview</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>df_scheduled_interviewer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          df_application  df_department  df_interview  df_job  \\\n",
       "df_application                         0              0             0       0   \n",
       "df_department                          0              0             0       0   \n",
       "df_interview                           0              0             0       0   \n",
       "df_job                                 0              0             0       0   \n",
       "df_job_application                     0              0             0       0   \n",
       "df_job_department                      0              0             0       0   \n",
       "df_job_post                            0              0             0       0   \n",
       "df_job_stage                           0              0             1       0   \n",
       "df_scheduled_interview                 0              0             0       0   \n",
       "df_scheduled_interviewer               0              0             0       0   \n",
       "\n",
       "                          df_job_application  df_job_department  df_job_post  \\\n",
       "df_application                             1                  0            0   \n",
       "df_department                              0                  1            0   \n",
       "df_interview                               0                  0            0   \n",
       "df_job                                     1                  1            1   \n",
       "df_job_application                         0                  0            0   \n",
       "df_job_department                          0                  0            0   \n",
       "df_job_post                                0                  0            0   \n",
       "df_job_stage                               0                  0            0   \n",
       "df_scheduled_interview                     0                  0            0   \n",
       "df_scheduled_interviewer                   0                  0            0   \n",
       "\n",
       "                          df_job_stage  df_scheduled_interview  \\\n",
       "df_application                       0                       1   \n",
       "df_department                        0                       0   \n",
       "df_interview                         0                       1   \n",
       "df_job                               1                       0   \n",
       "df_job_application                   0                       0   \n",
       "df_job_department                    0                       0   \n",
       "df_job_post                          0                       0   \n",
       "df_job_stage                         0                       0   \n",
       "df_scheduled_interview               0                       0   \n",
       "df_scheduled_interviewer             0                       0   \n",
       "\n",
       "                          df_scheduled_interviewer  \n",
       "df_application                                   0  \n",
       "df_department                                    0  \n",
       "df_interview                                     0  \n",
       "df_job                                           0  \n",
       "df_job_application                               0  \n",
       "df_job_department                                0  \n",
       "df_job_post                                      0  \n",
       "df_job_stage                                     0  \n",
       "df_scheduled_interview                           1  \n",
       "df_scheduled_interviewer                         0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship_list = []\n",
    "\n",
    "# Iterate through each dataset item in the list. \n",
    "# The 'current' item will be the item that all other list items will be compared to in each iteration\n",
    "for index, current in enumerate(datasets):\n",
    "  \n",
    "    current_relationship_list = []\n",
    "    \n",
    "    # Iterate through each item in the dataset, to compare to the 'current' item\n",
    "    for new_index, iterator in enumerate(datasets):\n",
    "        \n",
    "        # Construct a preliminary relational column name\n",
    "        relational_id_name = '{}_id'.format(dataset_names[index].replace('df_',''))\n",
    "        \n",
    "        # If relational id name in the columns\n",
    "        if (relational_id_name in iterator.columns):\n",
    "                        \n",
    "            current_relationship_list.append(1)\n",
    "            \n",
    "        # Default case, add 0\n",
    "        else:\n",
    "            \n",
    "            current_relationship_list.append(0)\n",
    "        \n",
    "    relationship_list.append(current_relationship_list)\n",
    "        \n",
    "# Create 'auto-detect' relationship matrix\n",
    "array = np.array(relationship_list)\n",
    "\n",
    "df_relationship_matrix = pd.DataFrame(data = array, \n",
    "                  index = dataset_names, \n",
    "                  columns = dataset_names)\n",
    "\n",
    "df_relationship_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, with special focus on application and interview, the following relationships may be grouped together:\n",
    "* Application\n",
    "    * df_application > df_job_application > df_job\n",
    "    * df_application > df_scheduled_interview > df_interview > df_job_stage > df_job\n",
    "* Interviews\n",
    "    * df_interview > df_job_stage > df_job\n",
    "    * df_interview > df_scheduled_interview > df_scheduled_interview > df_application > df_job_application > df_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Datasets: Similarities\n",
    "In a case where data structure merges would be automated, there will be issues when merging tables with the same column headings, representing different data. These similiarities should be handled as 'exceptions' with careful attention on renaming them appropriately before applying merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarities</th>\n",
       "      <th>Current Dataset</th>\n",
       "      <th>Number of Similarities</th>\n",
       "      <th>Iterated Dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['status']</td>\n",
       "      <td>df_job</td>\n",
       "      <td>1</td>\n",
       "      <td>df_application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>['status']</td>\n",
       "      <td>df_scheduled_interview</td>\n",
       "      <td>1</td>\n",
       "      <td>df_application</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['name']</td>\n",
       "      <td>df_interview</td>\n",
       "      <td>1</td>\n",
       "      <td>df_department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['name']</td>\n",
       "      <td>df_job</td>\n",
       "      <td>1</td>\n",
       "      <td>df_department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>['name']</td>\n",
       "      <td>df_job_stage</td>\n",
       "      <td>1</td>\n",
       "      <td>df_department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['name']</td>\n",
       "      <td>df_department</td>\n",
       "      <td>1</td>\n",
       "      <td>df_interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['name']</td>\n",
       "      <td>df_job</td>\n",
       "      <td>1</td>\n",
       "      <td>df_interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>['name']</td>\n",
       "      <td>df_job_stage</td>\n",
       "      <td>1</td>\n",
       "      <td>df_interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['status']</td>\n",
       "      <td>df_application</td>\n",
       "      <td>1</td>\n",
       "      <td>df_job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['name']</td>\n",
       "      <td>df_department</td>\n",
       "      <td>1</td>\n",
       "      <td>df_job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['name']</td>\n",
       "      <td>df_interview</td>\n",
       "      <td>1</td>\n",
       "      <td>df_job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>['created_at']</td>\n",
       "      <td>df_job_post</td>\n",
       "      <td>1</td>\n",
       "      <td>df_job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>['created_at']</td>\n",
       "      <td>df_job</td>\n",
       "      <td>1</td>\n",
       "      <td>df_job_post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['name']</td>\n",
       "      <td>df_department</td>\n",
       "      <td>1</td>\n",
       "      <td>df_job_stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['name']</td>\n",
       "      <td>df_interview</td>\n",
       "      <td>1</td>\n",
       "      <td>df_job_stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['status']</td>\n",
       "      <td>df_application</td>\n",
       "      <td>1</td>\n",
       "      <td>df_scheduled_interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>['created_at', 'name']</td>\n",
       "      <td>df_job_stage</td>\n",
       "      <td>2</td>\n",
       "      <td>df_job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>['created_at', 'status']</td>\n",
       "      <td>df_scheduled_interview</td>\n",
       "      <td>2</td>\n",
       "      <td>df_job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>['created_at', 'updated_at']</td>\n",
       "      <td>df_job_stage</td>\n",
       "      <td>2</td>\n",
       "      <td>df_job_post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>['created_at', 'updated_at']</td>\n",
       "      <td>df_scheduled_interview</td>\n",
       "      <td>2</td>\n",
       "      <td>df_job_post</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['created_at', 'name']</td>\n",
       "      <td>df_job</td>\n",
       "      <td>2</td>\n",
       "      <td>df_job_stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>['created_at', 'updated_at']</td>\n",
       "      <td>df_job_post</td>\n",
       "      <td>2</td>\n",
       "      <td>df_job_stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>['created_at', 'updated_at']</td>\n",
       "      <td>df_scheduled_interview</td>\n",
       "      <td>2</td>\n",
       "      <td>df_job_stage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>['created_at', 'status']</td>\n",
       "      <td>df_job</td>\n",
       "      <td>2</td>\n",
       "      <td>df_scheduled_interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>['created_at', 'updated_at']</td>\n",
       "      <td>df_job_post</td>\n",
       "      <td>2</td>\n",
       "      <td>df_scheduled_interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>['created_at', 'updated_at']</td>\n",
       "      <td>df_job_stage</td>\n",
       "      <td>2</td>\n",
       "      <td>df_scheduled_interview</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Similarities         Current Dataset  \\\n",
       "8                     ['status']                  df_job   \n",
       "22                    ['status']  df_scheduled_interview   \n",
       "5                       ['name']            df_interview   \n",
       "9                       ['name']                  df_job   \n",
       "17                      ['name']            df_job_stage   \n",
       "2                       ['name']           df_department   \n",
       "10                      ['name']                  df_job   \n",
       "18                      ['name']            df_job_stage   \n",
       "0                     ['status']          df_application   \n",
       "3                       ['name']           df_department   \n",
       "6                       ['name']            df_interview   \n",
       "14                ['created_at']             df_job_post   \n",
       "11                ['created_at']                  df_job   \n",
       "4                       ['name']           df_department   \n",
       "7                       ['name']            df_interview   \n",
       "1                     ['status']          df_application   \n",
       "19        ['created_at', 'name']            df_job_stage   \n",
       "23      ['created_at', 'status']  df_scheduled_interview   \n",
       "20  ['created_at', 'updated_at']            df_job_stage   \n",
       "24  ['created_at', 'updated_at']  df_scheduled_interview   \n",
       "12        ['created_at', 'name']                  df_job   \n",
       "15  ['created_at', 'updated_at']             df_job_post   \n",
       "25  ['created_at', 'updated_at']  df_scheduled_interview   \n",
       "13      ['created_at', 'status']                  df_job   \n",
       "16  ['created_at', 'updated_at']             df_job_post   \n",
       "21  ['created_at', 'updated_at']            df_job_stage   \n",
       "\n",
       "   Number of Similarities        Iterated Dataset  \n",
       "8                       1          df_application  \n",
       "22                      1          df_application  \n",
       "5                       1           df_department  \n",
       "9                       1           df_department  \n",
       "17                      1           df_department  \n",
       "2                       1            df_interview  \n",
       "10                      1            df_interview  \n",
       "18                      1            df_interview  \n",
       "0                       1                  df_job  \n",
       "3                       1                  df_job  \n",
       "6                       1                  df_job  \n",
       "14                      1                  df_job  \n",
       "11                      1             df_job_post  \n",
       "4                       1            df_job_stage  \n",
       "7                       1            df_job_stage  \n",
       "1                       1  df_scheduled_interview  \n",
       "19                      2                  df_job  \n",
       "23                      2                  df_job  \n",
       "20                      2             df_job_post  \n",
       "24                      2             df_job_post  \n",
       "12                      2            df_job_stage  \n",
       "15                      2            df_job_stage  \n",
       "25                      2            df_job_stage  \n",
       "13                      2  df_scheduled_interview  \n",
       "16                      2  df_scheduled_interview  \n",
       "21                      2  df_scheduled_interview  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_similiarities = pd.DataFrame(columns={'Current Dataset', 'Iterated Dataset', 'Number of Similarities', 'Similarities'})\n",
    "\n",
    "# Iterate through each dataset item in the list. \n",
    "# The 'current' item will be the item that all other list items will be compared to in each iteration\n",
    "for index, current in enumerate(datasets):\n",
    "  \n",
    "    current_relationship_list = []\n",
    "    \n",
    "    # Iterate through each item in the dataset, to compare to the 'current' item\n",
    "    for new_index, iterator in enumerate(datasets):\n",
    "        \n",
    "        # Get the same columns between datasets\n",
    "        same = np.intersect1d(current.columns, iterator.columns)\n",
    "        \n",
    "        # Filter out fivetran results\n",
    "        same_filtered = list(filter(lambda k: ('fivetran' not in k) and ('id' not in k), same))\n",
    "        \n",
    "        if (same_filtered != []) and (dataset_names[index] != dataset_names[new_index]):\n",
    "            \n",
    "            # Test Harness: Print number of same fields\n",
    "            #print('{} - {}'.format(dataset_names[index], dataset_names[new_index]))\n",
    "            #print(len(same_filtered))\n",
    "            \n",
    "            # Append similarity record to the dataframe (excluding 'id' column)\n",
    "            df_similiarities = df_similiarities.append({'Current Dataset': dataset_names[index], 'Iterated Dataset': dataset_names[new_index], 'Number of Similarities': len(same_filtered), 'Similarities': str(same_filtered)}, ignore_index=True)\n",
    "            \n",
    "# Display similiarities dataframe by number of similarities in ascending order\n",
    "df_similiarities.sort_values(by=['Number of Similarities','Iterated Dataset'], ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, it can be seen that special attention should be paid to columns like 'status' and 'name' as well as create/update dates when merging datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Datasets\n",
    "\n",
    "Stage the raw data before performing necessary cleanup tasks and data transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applications dataset contains no blanks - data already cleaned - no major data cleanup necessary\n",
    "# Interviews dataset contains no blanks - data already cleaned - no major data cleanup necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join application to job_application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14456\n",
      "6048\n"
     ]
    }
   ],
   "source": [
    "# Pre-check to see what the counts are\n",
    "print(len(df_job_application))\n",
    "print(len(df_application))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application_dataset = df_application\n",
    "df_application_dataset = pd.merge(df_application_dataset, df_job_application, left_on='id', right_on='application_id', how='left')\n",
    "\n",
    "# Column Cleanup\n",
    "df_application_dataset = df_application_dataset.drop(columns = ['_fivetran_synced_x','_fivetran_synced_y'])\n",
    "df_application_dataset = df_application_dataset.rename(columns={'id': 'application_dataset_id', 'status': 'application_status'})\n",
    "\n",
    "# Data check: Only 4323 of the 6048 rows have job_id's attached to them\n",
    "#df_application_dataset[df_application_dataset['job_id'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join application_dataset to job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6048\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "# Pre-check to see what the counts are\n",
    "print(len(df_application_dataset))\n",
    "print(len(df_job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application_dataset_temp = pd.merge(df_application_dataset, df_job, left_on='job_id', right_on='id', how='left')\n",
    "\n",
    "# Column Cleanup\n",
    "df_application_dataset = df_application_dataset_temp.rename(columns={'id': 'job_job_id', 'status': 'job_status', 'name': 'job_name', 'created_at': 'job_created_at', 'closed_at': 'job_closed_at'})\n",
    "\n",
    "# Data check: Only 3388 of the 6048 rows have job id's attached to them\n",
    "#df_application_dataset[df_application_dataset['job_job_id'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join application_dataset to job_department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6048\n",
      "243\n"
     ]
    }
   ],
   "source": [
    "# Pre-check to see what the counts are\n",
    "print(len(df_application_dataset))\n",
    "print(len(df_job_department))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application_dataset_temp = pd.merge(df_application_dataset, df_job_department, left_on='job_id', right_on='job_id', how='left')\n",
    "\n",
    "# Column Cleanup\n",
    "df_application_dataset = df_application_dataset_temp.rename(columns={'id': 'department_id', 'job_id': 'department_job_id'})\n",
    "\n",
    "# Data check: Only 4323 of the 6048 rows have job id's attached to them\n",
    "#df_application_dataset[df_application_dataset['department_id'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join application_dataset to department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6048\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# Pre-check to see what the counts are\n",
    "print(len(df_application_dataset))\n",
    "print(len(df_department))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application_dataset_temp = pd.merge(df_application_dataset, df_department, left_on='department_id', right_on='id', how='left')\n",
    "\n",
    "# Column Cleanup\n",
    "df_application_dataset = df_application_dataset_temp.rename(columns={'id': 'department_department_id', 'name': 'department_name'})\n",
    "\n",
    "# Data check: Only 4323 of the 6048 rows have job id's attached to them\n",
    "#df_application_dataset[df_application_dataset['department_department_id'] > 0]\n",
    "\n",
    "# No departments with parent_id's brought over"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join application_dataset to job_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6048\n",
      "856\n"
     ]
    }
   ],
   "source": [
    "# Pre-check to see what the counts are\n",
    "print(len(df_application_dataset))\n",
    "print(len(df_job_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_application_dataset_temp = pd.merge(df_application_dataset, df_job_stage, left_on='job_job_id', right_on='job_id', how='left')\n",
    "\n",
    "# Column Cleanup\n",
    "df_application_dataset = df_application_dataset_temp.rename(columns={'id': 'job_stage_id', 'name': 'job_stage_name', 'created_at': 'job_stage_created_at', 'updated_at': 'job_stage_updated_at'})\n",
    "df_application_dataset = df_application_dataset.drop(columns = ['_fivetran_deleted_x','_fivetran_deleted_y'])\n",
    "\n",
    "df_application_dataset_temp = pd.merge(df_application_dataset, df_job_stage, left_on='current_stage_id', right_on='id', how='left')\n",
    "\n",
    "# Column Cleanup\n",
    "df_application_dataset = df_application_dataset_temp.rename(columns={'id': 'application_stage_id', 'name': 'application_stage_name', 'created_at': 'application_stage_created_at', 'updated_at': 'application_stage_updated_at'})\n",
    "\n",
    "# Data check: There are 29659 of 32267 records with a job stage id\n",
    "#df_application_dataset[df_application_dataset['job_stage_id'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32261\n"
     ]
    }
   ],
   "source": [
    "# Post-check to see what the counts are\n",
    "print(len(df_application_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup column selection\n",
    "df_application_dataset = df_application_dataset[['candidate_id', 'applied_at', 'rejected_at','last_activity_at', \n",
    "                                                 'prospect', 'location_address','application_status', 'is_deleted', \n",
    "                                                 'application_id', 'job_name', 'job_status', 'job_created_at','job_closed_at', \n",
    "                                                 'job_stage_name','application_stage_name','department_name']]\n",
    "\n",
    "# All columns that link to datasets that have not been provided (excluding candidate) have been removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join interview to scheduled_interview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2242\n",
      "846\n"
     ]
    }
   ],
   "source": [
    "# Pre-check to see what the counts are\n",
    "print(len(df_interview))\n",
    "print(len(df_scheduled_interview))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interview_dataset = df_interview\n",
    "df_interview_dataset_temp = pd.merge(df_interview, df_scheduled_interview, left_on='id', right_on='interview_id', how='left')\n",
    "\n",
    "# Column Cleanup\n",
    "df_interview_dataset = df_interview_dataset_temp.rename(columns={'name':'interview_name', 'id_y': 'scheduled_interview_id', 'id_x': 'interview_interview_id', 'status': 'interview_status', 'created_at': 'interview_created_at','updated_at': 'interview_updated_at', 'end': 'interview_end', 'start': 'interview_start'})\n",
    "\n",
    "# Data check: Only 820 of the 2242 rows have job_id's attached to them\n",
    "#df_interview_dataset[df_interview_dataset['scheduled_interview_id'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join interview to scheduled_interviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2773\n",
      "3694\n"
     ]
    }
   ],
   "source": [
    "# Pre-check to see what the counts are\n",
    "print(len(df_interview_dataset))\n",
    "print(len(df_scheduled_interviewer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interview_dataset_temp = pd.merge(df_interview_dataset, df_scheduled_interviewer, left_on='scheduled_interview_id', right_on='scheduled_interview_id', how='left')\n",
    "\n",
    "# Column Cleanup\n",
    "df_interview_dataset = df_interview_dataset_temp.rename(columns={'scheduled_interview_id_x': 'scheduled_interview_id', 'scheduled_interview_id_y': 'scheduled_interviewer_id'})\n",
    "\n",
    "# Data check: Only 1471 of the 2242 rows have job_id's attached to them\n",
    "#df_interview_dataset[df_interview_dataset['interviewer_id'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join interview to job_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424\n",
      "856\n"
     ]
    }
   ],
   "source": [
    "# Pre-check to see what the counts are\n",
    "print(len(df_interview_dataset))\n",
    "print(len(df_job_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interview_dataset_temp = pd.merge(df_interview_dataset, df_job_stage, left_on='job_stage_id', right_on='id', how='left')\n",
    "\n",
    "# Column Cleanup\n",
    "df_interview_dataset = df_interview_dataset_temp.rename(columns={'id': 'job_stage_job_stage_id', 'name': 'job_stage_name', 'created_at': 'job_stage_created_at', 'updated_at': 'job_stage_updated_at'})\n",
    "\n",
    "# Data check: Only 1824 of the 2242 rows have job_id's attached to them\n",
    "#df_interview_dataset[df_interview_dataset['job_stage_job_stage_id'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join interview to job_department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424\n",
      "243\n"
     ]
    }
   ],
   "source": [
    "# Pre-check to see what the counts are\n",
    "print(len(df_interview_dataset))\n",
    "print(len(df_job_department))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interview_dataset_temp = pd.merge(df_interview_dataset, df_job_department, left_on='job_id', right_on='job_id', how='left')\n",
    "\n",
    "# Column Cleanup\n",
    "df_interview_dataset = df_interview_dataset_temp.rename(columns={'job_id': 'job_department_job_id'})\n",
    "\n",
    "# Data check: Only 1824 of the 2242 rows have job_id's attached to them\n",
    "#df_interview_dataset[df_interview_dataset['department_id'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join interview to department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# Pre-check to see what the counts are\n",
    "print(len(df_interview_dataset))\n",
    "print(len(df_department))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interview_dataset_temp = pd.merge(df_interview_dataset, df_department, left_on='department_id', right_on='id', how='left')\n",
    "\n",
    "# Column Cleanup\n",
    "df_interview_dataset = df_interview_dataset_temp.rename(columns={'id': 'department_department_id', 'name': 'department_name'})\n",
    "\n",
    "# Data check: Only 1824 of the 2242 rows have job_id's attached to them\n",
    "#df_interview_dataset[df_interview_dataset['department_id'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join interview to job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424\n",
      "102\n"
     ]
    }
   ],
   "source": [
    "# Pre-check to see what the counts are\n",
    "print(len(df_interview_dataset))\n",
    "print(len(df_job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interview_dataset_temp = pd.merge(df_interview_dataset, df_job, left_on='job_department_job_id', right_on='id', how='left')\n",
    "\n",
    "# Column Cleanup\n",
    "df_interview_dataset = df_interview_dataset_temp.rename(columns={'id': 'job_id', 'name': 'job_name', 'status': 'job_status', 'created_at': 'job_created_at', 'closed_at':'job_closed_at'})\n",
    "\n",
    "# Data check: Only 1815 of the 2242 rows have job_id's attached to them\n",
    "#df_interview_dataset[df_interview_dataset['job_id'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3424\n"
     ]
    }
   ],
   "source": [
    "# Post-check to see what the counts are\n",
    "print(len(df_interview_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup column selection\n",
    "df_interview_dataset = df_interview_dataset[['interview_interview_id','interview_name','application_id', 'location',\n",
    "                                             'interview_status','interview_end', 'interview_start', 'interview_id', \n",
    "                                             'organizer_id','interviewer_id','job_stage_name',\n",
    "                                             'department_name', 'job_name','job_status', 'interview_created_at']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Datasets\n",
    "\n",
    "Create the required datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Check if path exists, if it doesn't, create the Generated file\n",
    "file_path += '\\Generated'\n",
    "\n",
    "df_application_dataset.to_csv(r'%s\\application.csv' % file_path, index=False)\n",
    "df_interview_dataset.to_csv(r'%s\\interview.csv' % file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two datasets have been imported into Power BI to be easily visualised according to the questions that were posed, namely:\n",
    "- Applications:\n",
    "    - Which jobs have the highest number of applications?\n",
    "    - What is the conversion rate between the stages of jobs?\n",
    "    - Which department has created the most job posts?\n",
    "- Interviews:\n",
    "    - Which jobs have the highest number of interviews?\n",
    "    - Which stages in the application have the highest number of interviews?\n",
    "    - Which interviewers perform the most interviews?\n",
    "    - Which department has performed the most interviews?\n",
    "    \n",
    "The Power BI report and the PDF version of the report (along with all other applicable resources) are available on <a href='http://github.com/JacquiM/Recruitment-Data-Engineering-and-Analysis'>Github</a>\n",
    "\n",
    "The PDF version of the report is available <a href='http://github.com/JacquiM/Recruitment-Data-Engineering-and-Analysis/blob/main/Report/Final%20Assessment%20Analysis.pdf'>here</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
